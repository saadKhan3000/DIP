{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0f68ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter of the object: 654.0\n",
      "Centroid of the object (x, y): (175, 136)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('rect1.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to obtain a binary image (assuming the object is in white color)\n",
    "_, thresholded = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the binary image\n",
    "contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Initialize variables to store the largest rectangle/square found\n",
    "largest_area = 0\n",
    "largest_rectangle = None\n",
    "\n",
    "# Iterate through the contours to find the largest rectangle/square\n",
    "for contour in contours:\n",
    "    # Approximate the contour as a polygon\n",
    "    epsilon = 0.04 * cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "    \n",
    "    # Check if the polygon has 4 corners (indicating a rectangle or square)\n",
    "    if len(approx) == 4:\n",
    "        # Calculate the area of the polygon\n",
    "        area = cv2.contourArea(approx)\n",
    "        \n",
    "        # Check if it's the largest area found so far\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            largest_rectangle = approx\n",
    "\n",
    "# If a rectangle/square is found, draw it on the original image\n",
    "if largest_rectangle is not None:\n",
    "    cv2.drawContours(image, [largest_rectangle], -1, (0, 255, 0), 2)  # Draw a green rectangle\n",
    "\n",
    "    # Calculate the perimeter of the rectangle/square\n",
    "    perimeter = cv2.arcLength(largest_rectangle, True)\n",
    "\n",
    "    # Calculate the centroid of the rectangle/square\n",
    "    M = cv2.moments(largest_rectangle)\n",
    "    centroid_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "    centroid_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "    # Display the perimeter and centroid\n",
    "    print(f\"Parameter of the object: {perimeter}\")\n",
    "    print(f\"Centroid of the object (x, y): ({centroid_x}, {centroid_y})\")\n",
    "\n",
    "    # Show the image with the detected rectangle\n",
    "    cv2.imshow('Image with Rectangle', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No rectangle/square found in the image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a95dd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 is a boy, Image 2 is a girl\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def determine_gender(image1_path, image2_path):\n",
    "    # Load the images\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "\n",
    "    # Perform color analysis (e.g., check for dominant colors)\n",
    "    def analyze_colors(image):\n",
    "        # Convert the image to the HSV color space\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define color ranges for red, blue, and pink (common colors associated with gender)\n",
    "        lower_red = np.array([0, 100, 100])\n",
    "        upper_red = np.array([10, 255, 255])\n",
    "        lower_blue = np.array([100, 100, 100])\n",
    "        upper_blue = np.array([140, 255, 255])\n",
    "        lower_pink = np.array([140, 100, 100])\n",
    "        upper_pink = np.array([170, 255, 255])\n",
    "\n",
    "        # Create masks for each color range\n",
    "        mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "        mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "        mask_pink = cv2.inRange(hsv, lower_pink, upper_pink)\n",
    "\n",
    "        # Count the number of pixels in each mask\n",
    "        red_pixels = cv2.countNonZero(mask_red)\n",
    "        blue_pixels = cv2.countNonZero(mask_blue)\n",
    "        pink_pixels = cv2.countNonZero(mask_pink)\n",
    "\n",
    "        return red_pixels, blue_pixels, pink_pixels\n",
    "\n",
    "    red_pixels1, blue_pixels1, pink_pixels1 = analyze_colors(image1)\n",
    "    red_pixels2, blue_pixels2, pink_pixels2 = analyze_colors(image2)\n",
    "\n",
    "    # Define heuristics for gender determination\n",
    "    # Calculate color dominance ratios\n",
    "    dominance_ratio1 = red_pixels1 / max(1, blue_pixels1 + pink_pixels1)\n",
    "    dominance_ratio2 = red_pixels2 / max(1, blue_pixels2 + pink_pixels2)\n",
    "\n",
    "    if dominance_ratio1 > dominance_ratio2:\n",
    "        return \"Image 1 is a boy, Image 2 is a girl\"\n",
    "    elif dominance_ratio2 > dominance_ratio1:\n",
    "        return \"Image 1 is a girl, Image 2 is a boy\"\n",
    "    else:\n",
    "        return \"Both images have similar color characteristics. Unable to determine gender.\"\n",
    "\n",
    "# Example usage:\n",
    "image1_path = 'fig3.jpg'  # Replace with the path to your boy image\n",
    "image2_path = 'fig4.jpg'  # Replace with the path to your girl image\n",
    "result = determine_gender(image1_path, image2_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d46075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def determine_blurriness(original_path, blurred_path):\n",
    "    # Load the original and blurred images\n",
    "    original_image = cv2.imread(original_path, cv2.IMREAD_GRAYSCALE)\n",
    "    blurred_image = cv2.imread(blurred_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Calculate the Laplacian variance for each image\n",
    "    original_laplacian_var = cv2.Laplacian(original_image, cv2.CV_64F).var()\n",
    "    blurred_laplacian_var = cv2.Laplacian(blurred_image, cv2.CV_64F).var()\n",
    "\n",
    "    # Define a threshold to distinguish between original and blurred images\n",
    "    threshold = 1000  # Adjust this threshold as needed\n",
    "\n",
    "    # Determine which image is blurred and which one is original\n",
    "    if blurred_laplacian_var < threshold:\n",
    "        return \"Blurred Image\", \"Original Image\"\n",
    "    else:\n",
    "        return \"Original Image\", \"Blurred Image\"\n",
    "\n",
    "# Example usage:\n",
    "original_image_path = 'fig5.jpg'  # Replace with the path to your original image\n",
    "blurred_image_path = 'fig5_blur.jpg'    # Replace with the path to your blurred image\n",
    "\n",
    "blurred_title, original_title = determine_blurriness(original_image_path, blurred_image_path)\n",
    "\n",
    "# Display the images with titles\n",
    "original_image = cv2.imread(original_image_path)\n",
    "blurred_image = cv2.imread(blurred_image_path)\n",
    "\n",
    "cv2.imshow(original_title, original_image)\n",
    "cv2.imshow(blurred_title, blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab941bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_color_bar_areas(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive thresholding to isolate the color bars\n",
    "    thresholded = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Initialize an empty list to store areas\n",
    "    areas = []\n",
    "\n",
    "    # Loop through each contour and calculate its area\n",
    "    for contour in contours:\n",
    "        # Calculate the area of the contour\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        # Find the centroid of the contour\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            cx, cy = 0, 0\n",
    "\n",
    "        # Draw the contour and label the area at the centroid with a very small font size\n",
    "        cv2.drawContours(image, [contour], -1, (0, 255, 0), 2)\n",
    "        cv2.putText(image, f\"Area: {area:.2f} px^2\", (cx - 40, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (0, 0, 255), 1)\n",
    "\n",
    "        # Append the area to the list\n",
    "        areas.append(area)\n",
    "\n",
    "    # Display the image with contours and area labels\n",
    "    cv2.imshow(\"Color Bars with Areas\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Return the areas of the color bars\n",
    "    return areas\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'fig1.jpg'  # Replace with the path to your image\n",
    "areas = find_color_bar_areas(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0604367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bar Area Covered(%):\n",
      "Yellow: 0.00%\n",
      "Light Gray: 97.43%\n",
      "Gray: 0.00%\n",
      "Dark Gray: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_percentage_area(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the color ranges for each colored bar\n",
    "    color_ranges = [\n",
    "        {\"name\": \"Yellow\", \"lower\": (25, 50, 50), \"upper\": (35, 255, 255)},\n",
    "        {\"name\": \"Light Gray\", \"lower\": (0, 0, 160), \"upper\": (90, 30, 255)},\n",
    "        {\"name\": \"Gray\", \"lower\": (0, 0, 90), \"upper\": (90, 30, 160)},\n",
    "        {\"name\": \"Dark Gray\", \"lower\": (0, 0, 0), \"upper\": (90, 30, 90)},\n",
    "    ]\n",
    "\n",
    "    # Create a mask for the red arrow\n",
    "    lower_red = np.array([0, 0, 150])\n",
    "    upper_red = np.array([50, 50, 255])\n",
    "    mask_red = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "\n",
    "    # Initialize a dictionary to store bar names and covered areas\n",
    "    results = {}\n",
    "\n",
    "    # Loop through each color range and find the corresponding bars\n",
    "    for color_range in color_ranges:\n",
    "        lower_color = np.array(color_range[\"lower\"])\n",
    "        upper_color = np.array(color_range[\"upper\"])\n",
    "\n",
    "        # Create a mask for the current color range\n",
    "        mask_color = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours_color, _ = cv2.findContours(mask_color, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Initialize the total area of bars in this color range\n",
    "        total_area = 0\n",
    "\n",
    "        # Loop through each detected contour in the color range\n",
    "        for contour in contours_color:\n",
    "            # Calculate the area of the current bar\n",
    "            bar_area = cv2.contourArea(contour)\n",
    "\n",
    "            # Add the bar area to the total area\n",
    "            total_area += bar_area\n",
    "\n",
    "        # Calculate the percentage area covered by the red arrow\n",
    "        if total_area > 0:\n",
    "            percentage_covered = (total_area / np.sum(mask_red / 255)) * 100\n",
    "        else:\n",
    "            percentage_covered = 0\n",
    "\n",
    "        # Store the results in the dictionary\n",
    "        results[color_range[\"name\"]] = percentage_covered\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'fig2.jpg'  # Replace with the path to your image\n",
    "percentage_areas = calculate_percentage_area(image_path)\n",
    "\n",
    "# Display the results\n",
    "print(\"Bar Area Covered(%):\")\n",
    "for color, percentage in percentage_areas.items():\n",
    "    print(f\"{color}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72efa26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part Measurements:\n",
      "Part\tMax Width\tMax Height\n",
      "Part 1\t36\t\t35\n",
      "Part 2\t13\t\t20\n",
      "Part 3\t36\t\t93\n",
      "Part 4\t41\t\t124\n",
      "Part 5\t96\t\t342\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def segment_and_measure_parts(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper HSV color thresholds for each part\n",
    "    color_ranges = [\n",
    "        {\"name\": \"Part 1\", \"lower\": (0, 0, 0), \"upper\": (179, 255, 60)},  # Define the HSV range for each part\n",
    "        {\"name\": \"Part 2\", \"lower\": (0, 0, 61), \"upper\": (179, 255, 120)},\n",
    "        {\"name\": \"Part 3\", \"lower\": (0, 0, 121), \"upper\": (179, 255, 180)},\n",
    "        {\"name\": \"Part 4\", \"lower\": (0, 0, 181), \"upper\": (179, 255, 240)},\n",
    "        {\"name\": \"Part 5\", \"lower\": (0, 0, 241), \"upper\": (179, 255, 255)},\n",
    "    ]\n",
    "\n",
    "    # Initialize a list to store measurements\n",
    "    measurements = []\n",
    "\n",
    "    # Loop through each defined color range\n",
    "    for color_range in color_ranges:\n",
    "        lower_color = np.array(color_range[\"lower\"], dtype=np.uint8)\n",
    "        upper_color = np.array(color_range[\"upper\"], dtype=np.uint8)\n",
    "\n",
    "        # Create a mask for the current color range\n",
    "        mask = cv2.inRange(hsv_image, lower_color, upper_color)\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Initialize maximum width and height\n",
    "        max_width = 0\n",
    "        max_height = 0\n",
    "\n",
    "        # Loop through each detected contour in the color range\n",
    "        for contour in contours:\n",
    "            # Find the bounding box of the contour\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Update maximum width and height\n",
    "            max_width = max(max_width, w)\n",
    "            max_height = max(max_height, h)\n",
    "\n",
    "            # Draw a rectangle around the part (for visualization)\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Append measurements to the list\n",
    "        measurements.append((color_range[\"name\"], max_width, max_height))\n",
    "\n",
    "    # Display the image with bounding boxes\n",
    "    cv2.imshow('Finger Parts with Bounding Boxes', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Display maximum width and height for each part\n",
    "    print(\"Part Measurements:\")\n",
    "    print(\"Part\\tMax Width\\tMax Height\")\n",
    "    for measurement in measurements:\n",
    "        part, max_width, max_height = measurement\n",
    "        print(f\"{part}\\t{max_width}\\t\\t{max_height}\")\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'finger-bones.jpg'  # Replace with the path to your image\n",
    "segment_and_measure_parts(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e6733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
