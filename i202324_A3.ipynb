{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad35b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def highlight_color_variations(image1, image2):\n",
    "    # Read the images\n",
    "    img1 = cv2.imread(image1)\n",
    "    img2 = cv2.imread(image2)\n",
    "\n",
    "    # Resize images to the same dimensions (optional)\n",
    "    img1 = cv2.resize(img1, (500, 500))\n",
    "    img2 = cv2.resize(img2, (500, 500))\n",
    "\n",
    "    # Convert images to Lab color space for better color representation\n",
    "    lab1 = cv2.cvtColor(img1, cv2.COLOR_BGR2Lab)\n",
    "    lab2 = cv2.cvtColor(img2, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "    # Compute the absolute difference between the two images\n",
    "    diff = cv2.absdiff(lab1, lab2)\n",
    "\n",
    "    # Split the Lab channels\n",
    "    l, a, b = cv2.split(diff)\n",
    "\n",
    "    # Threshold the images to highlight color differences\n",
    "    threshold = 30\n",
    "    _, thresh_a = cv2.threshold(a, threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, thresh_b = cv2.threshold(b, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Combine the thresholded images\n",
    "    color_diff = cv2.bitwise_or(thresh_a, thresh_b)\n",
    "\n",
    "    # Apply the color difference mask to the original image\n",
    "    result = cv2.bitwise_and(img1, img1, mask=color_diff)\n",
    "\n",
    "    # Display the original image and the highlighted color differences\n",
    "    cv2.imshow(\"Original Image\", img1)\n",
    "    cv2.imshow(\"Color Variations Highlighted\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "highlight_color_variations(\"Shades/shade/1.jpg\", \"Shades/shade/b.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e964787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_red_dots_and_distance(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to the HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the lower and upper bounds for red color in HSV\n",
    "    lower_red = np.array([0, 100, 100])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "\n",
    "    # Create a mask to extract red regions\n",
    "    mask1 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Define the lower and upper bounds for red color (wraparound in HSV)\n",
    "    lower_red = np.array([160, 100, 100])\n",
    "    upper_red = np.array([180, 255, 255])\n",
    "\n",
    "    # Create a mask to extract red regions\n",
    "    mask2 = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "    # Combine both masks to get the final mask\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours based on their x-coordinate\n",
    "    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[0])\n",
    "\n",
    "    # Extract the bounding boxes of the contours\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "\n",
    "    # Draw lines between opposite pairs of points and calculate horizontal distance\n",
    "    for i in range(0, len(bounding_boxes)-1, 2):\n",
    "        x1, y1, w1, h1 = bounding_boxes[i]\n",
    "        x2, y2, w2, h2 = bounding_boxes[i + 1]\n",
    "\n",
    "        # Calculate the horizontal distance\n",
    "        distance = abs(x2 - x1)\n",
    "\n",
    "        # Draw a line between opposite pairs of points\n",
    "        cv2.line(image, (x1 + w1 // 2, y1 + h1 // 2), (x2 + w2 // 2, y2 + h2 // 2), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the distance\n",
    "        cv2.putText(image, f\"{distance} pixels\", (min(x1, x2), min(y1, y2) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    image = cv2.resize(image, (400, 400))\n",
    "    # Display the image with lines and distances\n",
    "    cv2.imshow(\"Red Dots and Distances\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "find_red_dots_and_distance(\"distance3.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e979b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def identify_skipped_stitching(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply Canny edge detector\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours based on area to exclude small details\n",
    "    min_contour_area = 300\n",
    "    filtered_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
    "\n",
    "    # Draw a bounding box around the skipped stitching area\n",
    "    for contour in filtered_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the original image with the bounding box\n",
    "    cv2.imshow(\"Skipped Stitching Detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "identify_skipped_stitching(\"skip_fabric.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4722521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_video(video_path, output_file, threshold):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the video's frames per second (fps) and width\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "    # Create a VideoWriter object for the output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "\n",
    "    # Open a text file to write frame numbers and corresponding widths\n",
    "    with open(output_file, 'w') as text_file:\n",
    "        frame_number = 0\n",
    "\n",
    "        # Read the first frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Process video frames\n",
    "        while ret:\n",
    "            # Convert the frame to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Define a region of interest (ROI) for width measurement (red line in this case)\n",
    "            roi = gray[200:300, :]\n",
    "\n",
    "            # Apply edge detection (Canny)\n",
    "            edges = cv2.Canny(roi, 50, 150)\n",
    "\n",
    "            # Find contours in the ROI\n",
    "            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Check if contours are found\n",
    "            if contours:\n",
    "                # Get the bounding box of the first contour (assuming only one contour for simplicity)\n",
    "                x, y, w, h = cv2.boundingRect(contours[0])\n",
    "\n",
    "                # Check if the width is below the threshold\n",
    "                if w < threshold:\n",
    "                    # Save frame number and width to the text file\n",
    "                    text_file.write(f\"Frame {frame_number}: Width = {w}\\n\")\n",
    "\n",
    "                    # Draw a rectangle around the region of interest\n",
    "                    cv2.rectangle(frame, (0, 200), (width, 300), (0, 0, 255), 2)\n",
    "\n",
    "            # Write the frame with the rectangle to the output video\n",
    "            out.write(frame)\n",
    "\n",
    "            # Read the next frame\n",
    "            ret, frame = cap.read()\n",
    "            frame_number += 1\n",
    "\n",
    "    # Release video capture and writer objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = 'video_width.mp4'\n",
    "output_file = 'output_width_measurements.txt'\n",
    "threshold = 100  # Set your threshold value here\n",
    "process_video(video_path, output_file, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd13149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Ball Detected!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def detect_no_ball(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Read the first frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Define the ROI for front foot detection\n",
    "    roi = frame[300:600, 400:800]\n",
    "\n",
    "    # Create background subtractor\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while ret:\n",
    "        # Apply background subtraction to the ROI\n",
    "        fg_mask = bg_subtractor.apply(roi)\n",
    "\n",
    "        # Find contours in the foreground mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Check if any contours (moving objects) are detected\n",
    "        if contours:\n",
    "            # Assuming the first contour corresponds to the bowler's front foot\n",
    "            x, y, w, h = cv2.boundingRect(contours[0])\n",
    "\n",
    "            # Check if the front foot is past a certain position (threshold)\n",
    "            if x + w > 50:  # Adjust the threshold based on your specific scenario\n",
    "                print(\"No Ball Detected!\")\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        # Read the next frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = 'cricket-2.mp4'\n",
    "detect_no_ball(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cbaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
